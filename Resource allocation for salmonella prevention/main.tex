\documentclass[12pt, letterpaper]{article}
\usepackage{setspace}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{array}
\usepackage{longtable}
\usepackage{quotes}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{xcolor}

% set reference files
\usepackage{biblatex}
\addbibresource{references.bib}

% set margins
\usepackage{geometry}
\geometry{margin=1in}

% Remove paragraph indentation
\setlength{\parindent}{0pt}

\title{ECE 8725 Final Project Report\\
    \large Connecting Data Driven Optimization, Decision focused learning and Symbolic Regression}
\author{Qazi Zarif Ul Islam}

\onehalfspacing
\begin{document}
\maketitle

\section{Abstract}
Optimization problems often require finding the best combination of input
variables to achieve desired outcomes under given constraints. While traditional
Machine Learning (ML) techniques excel at predictive tasks, they often fail to
consider the downstream impact of their predictions on decisions. Conversely,
decision-focused techniques, which perturb inputs to achieve specific outcomes,
lack the ability to leverage observational data. This report first discusses
traditional methods of optimization without data and then with data and proposes
a simple yet novel framework, \textbf{Express Symbolically then Optimize (ESO)},
which integrates symbolic regression and optimization to derive interpretable
input-output relationships and subsequently optimize decision-making.

We discuss existing methods such as Stochastic Programming, Decision-Focused
Learning (DFL), and Data-Driven Control, highlighting their limitations in
addressing problems where explicit input-output functions are unavailable. The
ESO framework addresses these limitations by using symbolic regression to
uncover interpretable mathematical relationships from data, followed by
optimization based on these symbolic expressions. 

We conclude with some remarks about evaluating applications of this framework,
which we believe will require novel methods that use post-hoc analysis of
predictive models. 

\section{Introduction}


\textit{"Given some input data, output data, and a feasible input space, determine the optimal combination of input data to achieve the desired output"}â€”this is the fundamental problem we seek to address. 

For instance, consider a scenario where the per-unit profit for Product A and
Product B is unknown, but historical data on production quantities and
corresponding total profits is available. The task is to determine the optimal
production quantities of Product A and Product B to maximize profit, given
resource constraints, without explicit knowledge of per-unit profits.

The above problem is an adaptation of the conventional optimization problem
where a problem is provided in the form of a function, which is to be minimized
or maximized. Only this time, the functional form is not provided and instead,
we are provided \textit{observations} about the inputs and the resulting output.
Machine Learning (ML) and statistical methods have achieved remarkable success
in prediction and inference with such historical data. But predictive models do
not account for how the predictions affect downstream decisions or outcomes. On
the other hand, techniques that focus on permuting inputs to achieve certain
outcomes- henceforth called `Decision Focused techniques'- do not leverage
observations. Thus, we think it is important to bridge this gap by using
principles from both branches- Machine Learning and Decision Focused techniques
to tackle the problem at hand.

The rest of the paper is structured as follows. Section \ref{sec: Background}
discusses the background of Decision Focused techniques and promising techniques
from Machine learning that can be used to bridge the gap. Section \ref{sec:
formalization} formalizes the problem and briefly discusses how to tackle the
problem with an emerging area in Machine learning, \textbf{Decision Focused
Learning} and finally how to tackle it with the new proposed framework,
\textit{Express Symbolically, then Optimize}.


\section{Background}
\label{sec: Background}
ML techniques have been used primarily to make tasks more efficient, not to
induce social policy and decision \cite{ml_policy}. We trust qualitative
arguments when deciding where to build a hospital or where to put more health
care funding. One explanation for this is that we can determine biases in an
argument instantly and doing the same for a learner is much harder as there are
different kinds of biases and a plethora of experimental methods to discern them
\cite{bias}. Another reason for the insuitability of ML techniques in this area
is that the predictions do not take into account \textit{its own effects} on
downstream decisions. But where we have not trusted predictions, we have trusted
optimization and statistical testing. \textbf{Optimization techniques} have been
heavily relied on when a deterministic answer is deemed to exist. Examples of
such problems include The Travelling Salesman problem, The Knapsack problem,
etc. Apart from \textbf{stochastic programming}, a particular paradigm of
optimization method, these problems differ from Machine Learning problems in
that the problem is not solved using data but rather a fixed set of conditions.
This fixed set contains a function relating the inputs to the output and
equations that give the `feasible answer region'. But, there are numerous
problems where we don't have a function that gives the input-output relationship
but yet we want to optimize the inputs for either maximizing or minimizing the
output based on some constraints on the inputs. For example, one could collected
data on healthcare funding, number of different kinds of social establishments,
poverty rates and disease rates and may want to decide if more socio-economic
development is urgently needed or not. In this scenario, there is no known
function to optimize as the relationship between the socio-economic factors and
the disease rates is unknown. To solve this kind of problem, \textbf{stochastic
programming} tries to use a 2 stage approach where in stage 1, decisions are
taken in an outcome agnostic manner and in stage 2, the costs or benefits of
these decisions are evaluated in terms of a probabilistic objective, typically
the expected value of a performance function that incorporates randomness.. In
this way, stochastic programming effectively models uncertainty by leveraging
historical data or assumed distributions. The objective function is not directly
"learned" in a machine learning sense but rather constructed to incorporate
uncertainty and minimize the expected cost (or maximize expected benefit).
{\textbf{Genetic algorithms}} or Evolutionary Algorithms use search algorithms
inspired by population behaviours that exist in nature to solve optimization
problems \cite{Kruse2022}. Just as in the previous methods, the objective
function needs to be fully defined. Genetic algorithms truly shine when
minimizing functions that are extremely complex, containing many local
minima/maxima, for example the Rosenbrock or Rastrigin function
\cite{test_functions}.

Another area that contains techniques that lead to decisions from data is
\textbf{statistical hypothesis testing}. However, using hypothesis testing
requires knowledge of the underlying probability distributions and real world
data does not explicitly express the probability distribution it is generated
from. \textbf{Data driven control} provides a way to \textit{control} the input
variables and thereby, optimize them for a desired output however, requires
knowledge of the input-output relationships. When this relationship is unknown,
\textbf{system identification} is used to derive it. Data driven control and
system identification are usually applied to dynamic systems where the variables
describing the system changes with time. It is however possible to use another
variable as a proxy for time to hold information about how the system changes
with that proxy variable. First, we need to have a model structure, for example,

\begin{equation}
    y(k) + ay(k-1) = bu(k)
\end{equation}

Where \textbf{a} and \textbf{b} are adjustable (learnable) parameters. From this
model structure, we use historical (input, output) data to derive the learnable
parameters. Usually, the input and output data are recorded through time. If
we instead have static data, though it is possible to simply index every observation
and then use the indices as k, when the data is shuffled, it changes the dynamical 
system itself. Thus every shuffling order of the data gives a new dynamic system.
Besides, there is no inherent temporal information in the indices, they are simply
numbers with no physical or temporal meaning.

The above limitations called for new techniques that can optimize inputs simply
using historical data, by predicting the relationship between the inputs and
ouput and then using the predicted relationship to formulate an optimization
problem. \cite{Mandi_2024} proposed the name "\textbf{Predict, then optimize}"
for this framework and used the term `\textbf{Decision Focused Learning}' (DFL) to
describe the techniques. To our knowledge, \cite{spo} was the first to propose
such a method, wherein a trained predictive model was used to predict a cost
vector, given an input vector, and then the cost vector and input vector were
used to form an objective function for an optimizer to solve. The simplest
representation of such an objective function is,

\begin{equation}
    f(\mathbf{x}, \mathbf{c}) = \mathbf{x}.{\mathbf{c}}
\end{equation}

The predictive model needs to be trained in a supervised manner and so, we must
bear knowledge of how each variable in the input vector $\mathbf{x}$
individually affects the function $f$, which is not available in many real-world
scenarios. To our knowledge, \cite{Google_DFL}, was the first to apply DFL in a
real-world scenario to optimize the scheduling of live service calls in a
maternal and child health awareness program. They used socio-demographic
features (e.g., age, income, education) and historical engagement states (e.g.,
whether beneficiaries listened to calls) as inputs, while the engagement
outcomes (e.g., listening behavior) served as outputs. The model predicted
transition probabilities between engagement states (engaging/non-engaging) under
different actions (call/no call). These predicted probabilities were used to
compute Whittle Indices \cite{P.Whittle}, which prioritized beneficiaries for
live service calls based on their potential to benefit. 

Decision Focused Learning incorporates the decision making into the learning
algorithm (typically Backpropagation with Neural Networks). The function of the
decision, $f(\mathbf{x^*(\hat{c}))}$, is often non-differentiable and this poses
significant challenges in applying DFL \cite{Mandi_2024}. We can use a more
simplified approach wherein we are given input-output pairs, $\mathbf{(x,y)}$
and we have to produce a symbolic function, expressing the mapping between the
input and output. Thus, in the end, the problem is simply one of
\textbf{symbolic regression} (SR). After the symbolic expression of the function
is obtained via symbolic regression, we use it as the objective function.
Symbolic regression has been used to add a layer of `interpretability' to black
box machine learning methods that learn functions. We start with a set of
possible arithmetic operators known as the `library' and define the
dimensionality of the function space. For example, a library could be $L=\{
id(.), add(.,.), sub(.,.), mul(.,.), +1, -1\}$. This particular library can
compose the set of all polynomials in one variable with integer coefficients
\cite{SR_2024}. \cite{SR_2024} conducted a comprehensive survey on SR methods
and divided the techniques into 4 fundamental types; (1) Regression based
methods (2) Tree based methods (3) Physics inspired methods and (4) Mathematics
inspired methods. Genetic algorithms can actually be used as a tree based method
for SR. Recently, \textbf{Kolmogorov Arnold Networks} (KANs) were shown to
perform better at Symbolic Regression than any other method \cite{kans_2024}
\cite{yu2024kanmlpfairercomparison}. Kolmogorov Arnold networks have the same
skeleton as \textbf{Neural Networks} \cite{rumelhart1986learning}, but the
difference is KANs use learnable functions instead of real valued weights as the
edges of the computational graph. The vertices of the graph are simply summing
operators. The learnable activation functions is the main ingredient of KANs,
which are spline functions. This automatically produces the symbolic nature of
the learned function. In Neural Networks, this symbolic extraction is not as
easy. Thus, we propose using KANs to symbolically regress data and learn the
function that describes the relation between the inputs and output. Then using
the learned function as the objective function, solve the optimization problem.

In the following section. We discuss two approaches that we think could be adopted
to solve resource allocation problems based on historical data. 

\section{Formalization of the problem}
\label{sec: formalization}
Suppose the goal is to determine a combination of inputs $\{x\}_n$, constrained
by some conditions , that maximizes or minimizes an output, which is a function
of $\{x\}_n$. This problem can be described as,

% \begin{align}
%     \text{Given,}\\
%     f(\mathbf{x}) &= \mathbf{c.x},\\
%     g(\mathbf{x}) &\geq 0,\\

%     \text{Determine,}\\
%     \mathbf{x^*} &= \arg \min_x f(\mathbf{x})
% \end{align}

\begin{align}
    \text{Given,}  & \\
    f(\mathbf{x}) &= \frac{1}{2}.\mathbf{x}^T.H.\mathbf{x} + \mathbf{c^T.x}, \\
    g(\mathbf{x}) &\geq 0, \\
    h(\mathbf{x}) &= 0 \\
    \text{Determine,} & \\
    \mathbf{x}^* &= \arg \min_{\mathbf{x}} f(\mathbf{x}),
\end{align}

Where $H$ and $\mathbf{c}$ represent coefficients and are unknown. Fortunately,
ML techniques provide a way to estimate these matrices from data. If
$\mathbf{\hat{H}}$ and $\hat{\mathbf{c}}$ are the predicted coefficients, the
problem becomes a quadratic programming problem like below.

\begin{align}
    \text{Given,}  & \\
    f(\mathbf{x}) &= \frac{1}{2}.\mathbf{x}^T.\hat{H}.\mathbf{x} + \mathbf{\hat{c}^T.x}, \\
    g(\mathbf{x}) &\geq 0, \\
    h(\mathbf{x}) &= 0 \\
    \text{Determine,} & \\
    \mathbf{x}^*(\hat{H}, \hat{\mathbf{c}}) &= \arg \min_{\mathbf{x}} f(\mathbf{x}, \hat{H}, \hat{\mathbf{c}}),
\end{align}

Where $\mathbf{x}^*$ is a function of $\hat{H}$ and $\hat{\mathbf{c}}$ because
it is dependent on the predictions made by the learner. 

There are two ways of approaching this problem: (1) Modifying the ML learner so
that it incorporates the optimization problem into its learning algorithm or,
(2) Predicting and then, optimizing, which follows the method in \cite{spo}.

\subsection{Decision Focused learning (DFL)}
The core aspect of this approach is to incorporate the \textit{decision} derived
from the prediction, $\hat{\mathbf{c}}$,  into the learning algorithm. This is
done by quantifying the accuracy of the decision \textit{based on} the
prediction ($\mathbf{x}^*(\hat{\mathbf{c}})$), which we call \textit{Regret}.
The Regret is formally expressed below.

\begin{equation}
    Regret(\mathbf{x}^*(\hat{\mathbf{c}})) = f(\mathbf{x}^*(\hat{\mathbf{c}}), \mathbf{c}) - f(\mathbf{x}^*(\mathbf{c}), \mathbf{c})
\end{equation}

Where $f(\mathbf{x}^*(\mathbf{c}), \mathbf{c})$ is the decision that would have
been obtained had the optimizer exact knowledge of $\mathbf{c}$.
$f(\mathbf{x}^*(\mathbf{c}), \mathbf{c})$ is known as `full information
decision'. Here, as $\hat{\mathbf{c}} \rightarrow \mathbf{c}$, $Regret
\rightarrow 0$. So, the better the prediction, the lower the regret. Instead of
making a point estimation, it is also possible to estimate the distribution of
$\hat{\mathbf{c}}$ so that it is possible to guard against the worst case using
the distributional knowledge, however more challenging. We refer the reader to
\cite{Mandi_2024} for a more comprehensive overview of the learning algorithm.

\subsection{Express Symbolically, then optimize (ESO)}
In this method we follow a 2-stage procedure. In stage 1 we use symbolic
regression to determine the symbolic expression of the function that describes
the data. In stage 2 we use this function and the given constraints to determine
the optimal combination of inputs. Any symbolic regressor is viable. In the
future, we shall experiment with KANs and an ensemble of KANs in a
\textbf{Mixture of Experts} \cite{masoudnia_mixture_2014} manner to solve
several optimization problems simultaneously.

\section{Conclusions}
In this project, we discussed the techniques that are used to solve optimization
problems and how data driven methods can now adopt those techniques thanks to
symbolic regression. The approach is to first use symbolic regression and then
optimize. Besides analysing performance of different symbolic regressors, it is
important to study techniques to evaluate this 2 stage approach. Since, we are
essentially \textit{deriving} decisions from data, we imagine the type of
evaluation that is needed is post-hoc evaluation, after the decisions have been
prescribed and have been executed and further data has been collected on the
results. This is both a challenge and a novel way of evaluating predictive
models that affect downstream decisions. It brings into light that the
prediction may not be end of the workflow. 

\printbibliography
\end{document}